{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook: initialization.ipynb\n",
    "This notebook is used for scraping data and storing it in a directory for use in our classifier."
   ]
  },
  {
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "Load data, normalize json, combine with bot identification\n",
    "\n",
    "Dataset are from [OSoMe botometer](https://botometer.osome.iu.edu/bot-repository/datasets.html)\n",
    "\n",
    "| Dataset               | Bots  | Humans | Notes                  |\n",
    "|-----------------------|-------|--------|------------------------|\n",
    "| cresci-rtbust-2019    | 353   | 339    |                        |\n",
    "| midterm-2018          | 42445 | 8092   |                        |\n",
    "| gilani-2017           | 1089  | 1413   |                        |\n",
    "| pronbots-2019         | 17881 | 0      | Spam bots              |\n",
    "| vendor-purchased-2019 | 1086  | 0      | Fake follower accounts |"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "with open('../datasets/cresci-rtbust-2019_tweets.json') as jsfile:\n",
    "    cresci_rtbust_2019_data = json.load(jsfile)\n",
    "cresci_rtbust_2019_data = json_normalize(cresci_rtbust_2019_data)\n",
    "cresci_rtbust_2019_data.rename(columns= {'created_at': 'probe_timestamp', 'user.id': 'user-id'}, inplace=True)\n",
    "cresci_rtbust_2019_data.columns = cresci_rtbust_2019_data.columns.str.replace(r'^user\\.','')\n",
    "\n",
    "cresci_rtbust_2019_identification = pd.read_csv('../datasets/cresci-rtbust-2019.tsv', sep='\\t')\n",
    "cresci_rtbust_2019_identification.columns = ['user-id','identification']\n",
    "cresci_rtbust_2019 = pd.merge(cresci_rtbust_2019_identification, cresci_rtbust_2019_data, how='inner', on='user-id')"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "Filter users that were active in the past 7 days that we have Tweets for"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cresci_rtbust_2019_tweet_data = pd.read_json('../tweets/cresci_rtbust_2019.json')\n",
    "active_users = cresci_rtbust_2019_tweet_data[(cresci_rtbust_2019_tweet_data.recent_tweets > 0)]\n",
    "cresci_rtbust_2019_active = pd.merge(active_users, cresci_rtbust_2019, how='inner', on='screen_name')\n",
    "cresci_rtbust_2019_active_bots = cresci_rtbust_2019_active[(cresci_rtbust_2019_active.identification=='bot')]\n",
    "cresci_rtbust_2019_active_humans = cresci_rtbust_2019_active[(cresci_rtbust_2019_active.identification=='human')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cresci_rtbust_2019_active_bots.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "cresci_rtbust_2019_active_humans.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "midterm_2018_data = pd.read_json('../datasets/midterm-2018_processed_user_objects.json')\n",
    "midterm_2018_identification = pd.read_csv('../datasets/midterm-2018.tsv', sep='\\t')\n",
    "midterm_2018_identification.columns = ['user_id','identification']\n",
    "midterm_2018 = pd.merge(midterm_2018_data, midterm_2018_identification, how='inner', on='user_id')\n",
    "midterm_2018_bots = midterm_2018[(midterm_2018.identification=='bot')]\n",
    "midterm_2018_humans = midterm_2018[(midterm_2018.identification=='human')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/gilani-2017_tweets.json') as jsfile:\n",
    "    gilani_2017_data = json.load(jsfile)\n",
    "gilani_2017_data = json_normalize(gilani_2017_data)\n",
    "gilani_2017_data.rename(columns= {'created_at': 'probe_timestamp', 'user.id': 'user-id'}, inplace=True)\n",
    "gilani_2017_data.columns = gilani_2017_data.columns.str.replace(r'^user\\.','')\n",
    "\n",
    "gilani_2017_identification = pd.read_csv('../datasets/gilani-2017.tsv', sep='\\t')\n",
    "gilani_2017_identification.columns = ['user-id','identification']\n",
    "gilani_2017 = pd.merge(gilani_2017_identification, gilani_2017_data, how='inner', on='user-id')\n",
    "gilani_2017_bots = gilani_2017[(gilani_2017.identification=='bot')]\n",
    "gilani_2017_humans = gilani_2017[(gilani_2017.identification=='human')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/pronbots-2019_tweets.json') as jsfile:\n",
    "    pronbots_2019_data = json.load(jsfile)\n",
    "pronbots_2019_data = json_normalize(pronbots_2019_data)\n",
    "pronbots_2019_data.rename(columns= {'created_at': 'probe_timestamp', 'user.id': 'user-id'}, inplace=True)\n",
    "pronbots_2019_data.columns = pronbots_2019_data.columns.str.replace(r'^user\\.','')\n",
    "\n",
    "pronbots_2019_identification = pd.read_csv('../datasets/pronbots-2019.tsv', sep='\\t')\n",
    "pronbots_2019_identification.columns = ['user-id','identification']\n",
    "pronbots_2019 = pd.merge(pronbots_2019_identification, pronbots_2019_data, how='inner', on='user-id')\n",
    "pronbots_2019_bots = pronbots_2019[(pronbots_2019.identification=='bot')]\n",
    "pronbots_2019_humans = pronbots_2019[(pronbots_2019.identification=='human')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/vendor-purchased-2019_tweets.json') as jsfile:\n",
    "    vendor_purchased_2019_data = json.load(jsfile)\n",
    "vendor_purchased_2019_data = json_normalize(vendor_purchased_2019_data)\n",
    "vendor_purchased_2019_data.rename(columns= {'created_at': 'probe_timestamp', 'user.id': 'user-id'}, inplace=True)\n",
    "vendor_purchased_2019_data.columns = vendor_purchased_2019_data.columns.str.replace(r'^user\\.','')\n",
    "\n",
    "vendor_purchased_2019_identification = pd.read_csv('../datasets/vendor-purchased-2019.tsv', sep='\\t')\n",
    "vendor_purchased_2019_identification.columns = ['user-id','identification']\n",
    "vendor_purchased_2019 = pd.merge(vendor_purchased_2019_identification, vendor_purchased_2019_data, how='inner', on='user-id')\n",
    "vendor_purchased_2019_bots = vendor_purchased_2019[(vendor_purchased_2019.identification=='bot')]\n",
    "vendor_purchased_2019_humans = vendor_purchased_2019[(vendor_purchased_2019.identification=='human')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}